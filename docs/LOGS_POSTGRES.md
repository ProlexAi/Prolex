# ğŸ“Š Logs PostgreSQL - Documentation ComplÃ¨te

> **SystÃ¨me de logging centralisÃ© pour Prolex v4+**
> **Date**: 2025-11-23
> **Version**: 1.0
> **Status**: Production Ready

---

## ğŸ“‹ Table des MatiÃ¨res

1. [Vue d'ensemble](#vue-densemble)
2. [Architecture](#architecture)
3. [SchÃ©ma de la table `app_logs`](#schÃ©ma-de-la-table-app_logs)
4. [Installation & Configuration](#installation--configuration)
5. [Utilisation](#utilisation)
6. [Client TypeScript (`dbClient.ts`)](#client-typescript-dbclientts)
7. [Outil MCP `log_event`](#outil-mcp-log_event)
8. [RequÃªtes SQL Utiles](#requÃªtes-sql-utiles)
9. [Monitoring & Maintenance](#monitoring--maintenance)
10. [Roadmap Future (LogRAG/AIOps)](#roadmap-future-logragiops)

---

## ğŸ¯ Vue d'ensemble

### Objectif

Prolex utilise dÃ©sormais **PostgreSQL comme systÃ¨me de logging centralisÃ©** pour tous les composants du systÃ¨me :

- **n8n** (workflows, exÃ©cutions)
- **MCP Servers** (n8n, Google, Finance, Communication, etc.)
- **Prolex Agent** (raisonnement, dÃ©cisions, actions)

### PrioritÃ©

âš ï¸ **IMPORTANT**: Les logs PostgreSQL sont maintenant **PRIORITAIRES** sur Google Sheets (SystemJournal).

**Pourquoi?**

- âœ… **Performance**: Ã‰criture et lecture ultra-rapides
- âœ… **RequÃªtes puissantes**: SQL pour analyses complexes
- âœ… **ScalabilitÃ©**: Gestion de millions de logs sans problÃ¨me
- âœ… **Indexation**: Recherche optimisÃ©e par source, niveau, date
- âœ… **DÃ©tails JSON**: Stockage flexible de mÃ©tadonnÃ©es avec JSONB
- âœ… **Future RAG**: PrÃ©paration pour LogRAG et AIOps (prochaine phase)

---

## ğŸ—ï¸ Architecture

### Flux de Logs

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PROLEX ECOSYSTEM                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   n8n    â”‚   â”‚ MCP n8n  â”‚   â”‚ MCP Comm â”‚   â”‚ Prolex  â”‚  â”‚
â”‚  â”‚Workflows â”‚   â”‚  Server  â”‚   â”‚  Server  â”‚   â”‚  Agent  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â”‚
â”‚       â”‚              â”‚              â”‚              â”‚        â”‚
â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚                           â”‚                                 â”‚
â”‚                      logEvent()                             â”‚
â”‚                           â”‚                                 â”‚
â”‚                           â–¼                                 â”‚
â”‚                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚
â”‚                  â”‚  dbClient.ts    â”‚ â† TypeScript Pool      â”‚
â”‚                  â”‚  (pg library)   â”‚                        â”‚
â”‚                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚
â”‚                           â”‚                                 â”‚
â”‚                           â–¼                                 â”‚
â”‚                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚
â”‚                  â”‚   PostgreSQL    â”‚                        â”‚
â”‚                  â”‚  (prolex-postgres)                      â”‚
â”‚                  â”‚                 â”‚                        â”‚
â”‚                  â”‚  Table:         â”‚                        â”‚
â”‚                  â”‚  app_logs       â”‚                        â”‚
â”‚                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Composants

| Composant | RÃ´le | Emplacement |
|-----------|------|-------------|
| **PostgreSQL 16** | Base de donnÃ©es centrale | `infra/vps-prod/docker-compose.yml` (service `postgres`) |
| **`app_logs` table** | Table de logs | CrÃ©Ã©e via `infra/db/migrations/0001_init_logs.sql` |
| **`dbClient.ts`** | Client TypeScript | `mcp/n8n-server/src/dbClient.ts` |
| **`log_event` tool** | Outil MCP | `mcp/n8n-server/src/tools/logEvent.ts` |
| **Migrations** | Scripts SQL | `infra/db/migrations/*.sql` |

---

## ğŸ“Š SchÃ©ma de la table `app_logs`

### Structure

```sql
CREATE TABLE app_logs (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
  source TEXT NOT NULL,
  level TEXT NOT NULL CHECK (level IN ('debug', 'info', 'warn', 'error')),
  message TEXT NOT NULL,
  details JSONB DEFAULT '{}'::jsonb
);
```

### Colonnes

| Colonne | Type | Description | Exemple |
|---------|------|-------------|---------|
| `id` | UUID | Identifiant unique | `a3f7e2c4-...` |
| `created_at` | TIMESTAMPTZ | Horodatage (timezone-aware) | `2025-11-23 14:32:15+00` |
| `source` | TEXT | Source du log | `"mcp_n8n"`, `"prolex_agent"`, `"n8n_workflow_123"` |
| `level` | TEXT | Niveau de log | `"debug"`, `"info"`, `"warn"`, `"error"` |
| `message` | TEXT | Message principal | `"Workflow executed successfully"` |
| `details` | JSONB | DÃ©tails additionnels (flexible) | `{"workflow_id": "abc123", "duration_ms": 1250}` |

### Index (Optimisation)

```sql
-- Index pour requÃªtes par date (DESC = plus rÃ©cents en premier)
CREATE INDEX idx_app_logs_created_at ON app_logs (created_at DESC);

-- Index pour filtrer par source
CREATE INDEX idx_app_logs_source ON app_logs (source);

-- Index pour filtrer par niveau
CREATE INDEX idx_app_logs_level ON app_logs (level);

-- Index composÃ©s pour requÃªtes combinÃ©es
CREATE INDEX idx_app_logs_source_created_at ON app_logs (source, created_at DESC);
CREATE INDEX idx_app_logs_level_created_at ON app_logs (level, created_at DESC);

-- Index GIN pour recherche JSON dans details
CREATE INDEX idx_app_logs_details_gin ON app_logs USING GIN (details);
```

**Pourquoi ces index?**

- **Performance**: RequÃªtes 10-100x plus rapides
- **RequÃªtes frÃ©quentes**: Filtrer par source, niveau, date
- **Recherche JSON**: Trouver des logs par champs dans `details`

---

## âš™ï¸ Installation & Configuration

### 1. DÃ©marrer PostgreSQL

```bash
# Depuis le rÃ©pertoire racine du projet
cd infra/vps-prod

# DÃ©marrer uniquement PostgreSQL
docker-compose up -d postgres

# VÃ©rifier que PostgreSQL est prÃªt
docker-compose logs -f postgres
# Attendre: "database system is ready to accept connections"
```

### 2. Configurer les variables d'environnement

Copier `.env.example` vers `.env` et configurer:

```bash
# PostgreSQL credentials
POSTGRES_USER=prolex_user
POSTGRES_PASSWORD=VOTRE_MOT_DE_PASSE_SECURISE
POSTGRES_DB=prolex_db

# URL de connexion (utilisÃ©e par les MCP servers)
DATABASE_URL=postgres://prolex_user:VOTRE_MOT_DE_PASSE@prolex-postgres:5432/prolex_db
```

âš ï¸ **IMPORTANT**:
- Ne JAMAIS committer le fichier `.env` (dÃ©jÃ  dans `.gitignore`)
- Utiliser un mot de passe fort en production

### 3. ExÃ©cuter les migrations

```bash
# Se placer dans le rÃ©pertoire des migrations
cd infra/db

# Rendre le script exÃ©cutable (une seule fois)
chmod +x migrate.sh

# ExÃ©cuter les migrations
./migrate.sh

# Ou avec une URL spÃ©cifique:
./migrate.sh "postgres://user:password@localhost:5432/dbname"
```

**Sortie attendue:**

```
ğŸ” VÃ©rification de psql...
âœ… psql installÃ©

ğŸ” VÃ©rification de DATABASE_URL...
âœ… DATABASE_URL chargÃ©e depuis .env

ğŸ”Œ Test de connexion Ã  PostgreSQL...
âœ… Connexion rÃ©ussie

ğŸ“¦ Application des migrations SQL...
âœ… Migration appliquÃ©e: 0001_init_logs.sql

âœ… Toutes les migrations ont Ã©tÃ© appliquÃ©es avec succÃ¨s!

ğŸ“Š VÃ©rification post-migration:
 schema_name | table_name
-------------+------------
 public      | app_logs
(1 row)
```

### 4. VÃ©rifier la table

```bash
# Se connecter Ã  PostgreSQL
docker exec -it prolex-postgres psql -U prolex_user -d prolex_db

# Lister les tables
\dt

# Voir le schÃ©ma de app_logs
\d app_logs

# Quitter
\q
```

---

## ğŸ’» Utilisation

### Option 1: Via l'outil MCP `log_event` (RecommandÃ© pour les agents IA)

**Depuis Claude Desktop** ou tout client MCP:

```typescript
// Appeler l'outil MCP log_event
{
  "source": "prolex_agent",
  "level": "info",
  "message": "Workflow design completed successfully",
  "details": {
    "workflow_id": "abc123",
    "duration_ms": 1250,
    "nodes_count": 15
  }
}
```

**RÃ©ponse:**

```json
{
  "success": true,
  "message": "âœ… Log enregistrÃ© dans PostgreSQL",
  "source": "prolex_agent",
  "level": "info",
  "timestamp": "2025-11-23T14:32:15.123Z"
}
```

### Option 2: Via le client TypeScript (Pour dÃ©veloppeurs)

**Dans un MCP server ou script Node.js:**

```typescript
import { logEvent, logError } from './dbClient.js';

// Exemple 1: Log simple
await logEvent({
  source: 'mcp_n8n',
  level: 'info',
  message: 'Workflow triggered successfully',
  details: {
    workflow_id: '123',
    execution_id: 'exec_456'
  }
});

// Exemple 2: Log d'erreur
try {
  await riskyOperation();
} catch (error) {
  await logError('mcp_n8n', error, {
    operation: 'riskyOperation',
    user_id: '789'
  });
}

// Exemple 3: Log de debug
await logEvent({
  source: 'prolex_agent',
  level: 'debug',
  message: 'RAG query executed',
  details: {
    query: 'How to create a workflow?',
    results_count: 5,
    latency_ms: 45
  }
});
```

### Option 3: SQL direct (Pour analyses)

```sql
-- InsÃ©rer un log manuellement
INSERT INTO app_logs (source, level, message, details)
VALUES (
  'manual_script',
  'info',
  'Database backup completed',
  '{"size_mb": 150, "duration_seconds": 30}'::jsonb
);
```

---

## ğŸ”§ Client TypeScript (`dbClient.ts`)

### API

#### `logEvent(input: LogEventInput): Promise<void>`

Enregistre un Ã©vÃ©nement dans PostgreSQL.

**Signature:**

```typescript
interface LogEventInput {
  source: string;         // Source du log (ex: "mcp_n8n")
  level: LogLevel;        // "debug" | "info" | "warn" | "error"
  message: string;        // Message principal
  details?: Record<string, unknown>; // DÃ©tails JSON (optionnel)
}
```

**Exemple:**

```typescript
await logEvent({
  source: 'mcp_google',
  level: 'info',
  message: 'Google Sheets updated',
  details: {
    spreadsheet_id: '1abc...',
    rows_updated: 42
  }
});
```

#### `logError(source: string, error: unknown, details?: Record<string, unknown>): Promise<void>`

Helper pour logger une erreur (niveau: `error`).

**Exemple:**

```typescript
try {
  await fetchDataFromAPI();
} catch (error) {
  await logError('mcp_communication', error, {
    api_endpoint: '/send_email',
    retry_count: 3
  });
}
```

#### `closePool(): Promise<void>`

Ferme proprement le pool de connexions (appelÃ© lors du shutdown).

**Note:** Le shutdown est automatique via les gestionnaires `SIGINT` et `SIGTERM`.

### Gestion des erreurs

Le client `dbClient.ts` est conÃ§u pour **ne jamais crasher le processus**:

- âŒ Si `DATABASE_URL` est absente â†’ Logs dÃ©sactivÃ©s (warning en console)
- âŒ Si PostgreSQL est inaccessible â†’ Erreur loggÃ©e en console uniquement
- âŒ Si une requÃªte Ã©choue â†’ Erreur loggÃ©e, processus continue

**Comportement de secours:**

```typescript
// Si PostgreSQL n'est pas disponible, dbClient.ts:
// 1. Affiche un warning en console
// 2. Retourne sans erreur (no-op)
// 3. Le processus continue normalement
```

---

## ğŸ› ï¸ Outil MCP `log_event`

### Description

L'outil `log_event` permet aux agents IA (Prolex, Claude, etc.) de s'auto-logger dans PostgreSQL.

**Autonomy Level:** 0+ (disponible Ã  tous les niveaux, mÃªme en read-only)

### SchÃ©ma MCP

```typescript
{
  name: 'log_event',
  description: 'ğŸ“ [v5] Write a log event to PostgreSQL central database. Use for agent self-logging and traceability.',
  inputSchema: {
    type: 'object',
    properties: {
      source: {
        type: 'string',
        description: 'Source of the log (e.g., "mcp_n8n", "prolex")',
        minLength: 1,
        maxLength: 50
      },
      level: {
        type: 'string',
        enum: ['debug', 'info', 'warn', 'error'],
        description: 'Log level'
      },
      message: {
        type: 'string',
        description: 'Log message (max 500 characters)',
        minLength: 1,
        maxLength: 500
      },
      details: {
        type: 'object',
        description: 'Optional additional details as JSON'
      }
    },
    required: ['source', 'level', 'message']
  }
}
```

### Exemples d'utilisation

#### Exemple 1: Log d'information

```json
{
  "source": "prolex_agent",
  "level": "info",
  "message": "Task planning completed",
  "details": {
    "task_id": "task_789",
    "steps_count": 5,
    "estimated_duration_minutes": 15
  }
}
```

#### Exemple 2: Log de warning

```json
{
  "source": "mcp_n8n",
  "level": "warn",
  "message": "Workflow execution slow",
  "details": {
    "workflow_id": "wf_123",
    "execution_time_ms": 5000,
    "threshold_ms": 2000
  }
}
```

#### Exemple 3: Log d'erreur

```json
{
  "source": "mcp_communication",
  "level": "error",
  "message": "Email sending failed",
  "details": {
    "email": "user@example.com",
    "error_code": "SMTP_TIMEOUT",
    "retry_attempt": 3
  }
}
```

---

## ğŸ“ˆ RequÃªtes SQL Utiles

### 1. Voir les 50 derniers logs

```sql
SELECT
  created_at,
  source,
  level,
  message,
  details
FROM app_logs
ORDER BY created_at DESC
LIMIT 50;
```

### 2. Filtrer par source

```sql
SELECT *
FROM app_logs
WHERE source = 'mcp_n8n'
ORDER BY created_at DESC
LIMIT 100;
```

### 3. Filtrer par niveau (erreurs uniquement)

```sql
SELECT *
FROM app_logs
WHERE level = 'error'
ORDER BY created_at DESC;
```

### 4. Logs des derniÃ¨res 24 heures

```sql
SELECT *
FROM app_logs
WHERE created_at >= NOW() - INTERVAL '24 hours'
ORDER BY created_at DESC;
```

### 5. Recherche dans les dÃ©tails JSON

```sql
-- Trouver tous les logs qui mentionnent un workflow_id spÃ©cifique
SELECT *
FROM app_logs
WHERE details->>'workflow_id' = 'abc123'
ORDER BY created_at DESC;

-- Trouver les exÃ©cutions lentes (> 2000ms)
SELECT *
FROM app_logs
WHERE (details->>'duration_ms')::int > 2000
ORDER BY created_at DESC;
```

### 6. Statistiques par source

```sql
SELECT
  source,
  COUNT(*) as total_logs,
  COUNT(*) FILTER (WHERE level = 'error') as errors,
  COUNT(*) FILTER (WHERE level = 'warn') as warnings,
  COUNT(*) FILTER (WHERE level = 'info') as infos,
  COUNT(*) FILTER (WHERE level = 'debug') as debugs
FROM app_logs
GROUP BY source
ORDER BY total_logs DESC;
```

### 7. Logs par heure (derniÃ¨res 24h)

```sql
SELECT
  DATE_TRUNC('hour', created_at) as hour,
  COUNT(*) as total_logs,
  COUNT(*) FILTER (WHERE level = 'error') as errors
FROM app_logs
WHERE created_at >= NOW() - INTERVAL '24 hours'
GROUP BY hour
ORDER BY hour DESC;
```

### 8. Recherche plein texte dans message

```sql
SELECT *
FROM app_logs
WHERE message ILIKE '%workflow%'
  AND created_at >= NOW() - INTERVAL '7 days'
ORDER BY created_at DESC;
```

---

## ğŸ” Monitoring & Maintenance

### Taille de la table

```sql
-- Voir la taille de la table app_logs
SELECT
  pg_size_pretty(pg_total_relation_size('app_logs')) AS total_size,
  pg_size_pretty(pg_relation_size('app_logs')) AS table_size,
  pg_size_pretty(pg_indexes_size('app_logs')) AS indexes_size;
```

### Nombre de logs

```sql
SELECT COUNT(*) as total_logs FROM app_logs;
```

### Purge des vieux logs (optionnel)

**âš ï¸ Ã€ utiliser avec prÃ©caution!**

```sql
-- Supprimer les logs de plus de 90 jours
DELETE FROM app_logs
WHERE created_at < NOW() - INTERVAL '90 days';

-- Vacuum pour libÃ©rer l'espace disque
VACUUM ANALYZE app_logs;
```

**Recommandation:** Configurer une tÃ¢che cron ou n8n workflow pour purger automatiquement.

### Backup des logs

```bash
# Exporter la table app_logs
docker exec prolex-postgres pg_dump -U prolex_user -d prolex_db -t app_logs > backup_app_logs.sql

# Restaurer depuis le backup
docker exec -i prolex-postgres psql -U prolex_user -d prolex_db < backup_app_logs.sql
```

---

## ğŸš€ Roadmap Future (LogRAG/AIOps)

### Phase 2: LogRAG (Q2 2025)

**Objectif:** Permettre Ã  Prolex de "raisonner" sur les logs avec RAG.

**FonctionnalitÃ©s:**

- âœ… **Vectorisation des logs**: Transformer les messages en embeddings
- âœ… **Recherche sÃ©mantique**: "Trouve les erreurs similaires Ã  celle-ci"
- âœ… **DÃ©tection de patterns**: Identifier automatiquement les problÃ¨mes rÃ©currents
- âœ… **Suggestions de fixes**: Prolex propose des solutions basÃ©es sur l'historique

**Stack technique:**

- **pgvector extension**: Stockage des embeddings dans PostgreSQL
- **OpenAI/Anthropic Embeddings**: GÃ©nÃ©ration des vecteurs
- **AnythingLLM integration**: Interface RAG

### Phase 3: AIOps (Q3 2025)

**Objectif:** Auto-rÃ©paration proactive basÃ©e sur les logs.

**FonctionnalitÃ©s:**

- âœ… **DÃ©tection d'anomalies**: ML pour identifier les comportements anormaux
- âœ… **Alertes prÃ©dictives**: Anticiper les pannes avant qu'elles n'arrivent
- âœ… **Auto-healing avancÃ©**: Corriger automatiquement les erreurs frÃ©quentes
- âœ… **Rapports intelligents**: RÃ©sumÃ©s quotidiens des insights

---

## ğŸ“ Notes Importantes

### SÃ©curitÃ©

- âœ… **Pas de secrets dans les logs**: Ne jamais logger des API keys, passwords, tokens
- âœ… **Sanitization**: Les donnÃ©es sensibles doivent Ãªtre masquÃ©es
- âœ… **AccÃ¨s restreint**: PostgreSQL accessible uniquement via rÃ©seau Docker (pas de port 5432 exposÃ© en prod)

### Performance

- âœ… **Pool de connexions**: `dbClient.ts` utilise un Pool (max 10 connexions)
- âœ… **Timeout**: 5 secondes pour Ã©viter les blocages
- âœ… **Index optimisÃ©s**: 6 index pour requÃªtes rapides
- âœ… **JSONB**: Stockage efficace avec recherche indexÃ©e

### CompatibilitÃ©

- âœ… **PostgreSQL 16**: Version utilisÃ©e (Alpine image)
- âœ… **pg library**: Version ^8.13.1
- âœ… **TypeScript**: Support natif avec types stricts
- âœ… **Docker**: Multi-architecture (amd64, arm64)

---

## ğŸ†˜ Support & Troubleshooting

### ProblÃ¨me: "DATABASE_URL non configurÃ©e"

**Solution:**

1. VÃ©rifier que le fichier `.env` existe dans `infra/vps-prod/`
2. VÃ©rifier que `DATABASE_URL` est dÃ©finie
3. RedÃ©marrer le MCP server

### ProblÃ¨me: "Erreur de connexion PostgreSQL"

**Solution:**

1. VÃ©rifier que PostgreSQL est dÃ©marrÃ©: `docker-compose ps postgres`
2. VÃ©rifier les logs: `docker-compose logs postgres`
3. Tester la connexion:
   ```bash
   docker exec -it prolex-postgres psql -U prolex_user -d prolex_db -c "SELECT 1;"
   ```

### ProblÃ¨me: "Table app_logs not found"

**Solution:**

1. ExÃ©cuter les migrations:
   ```bash
   cd infra/db && ./migrate.sh
   ```

---

## ğŸ“š RÃ©fÃ©rences

- **PostgreSQL Documentation**: https://www.postgresql.org/docs/16/
- **pg library**: https://node-postgres.com/
- **JSONB**: https://www.postgresql.org/docs/16/datatype-json.html
- **GIN Indexes**: https://www.postgresql.org/docs/16/gin-intro.html

---

**Document maintenu par:** Backend Team Prolex
**DerniÃ¨re mise Ã  jour:** 2025-11-23
**Version:** 1.0
**Status:** âœ… Production Ready
